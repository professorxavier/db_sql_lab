{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f79591-d1a0-44d5-b219-5a067c9f91ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Databricks-BR/lab_sql/main/images/header_notebook.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62dd77a1-0e46-4afe-95ff-14bfa7dac629",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descrição\n",
    "\n",
    "| projeto | aplicação | módulo | tabela | objetivo |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| ACADEMY | Laboratório 2 | ETL Bronze | Diversas CSV | Ingestão de arquivos publicos CSV - bases de teste para o Treinamento de SQL |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5af31e35-6373-417e-99d3-bfb57c499fd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Referências\n",
    "* [Leitura de Arquivos CSV](https://learn.microsoft.com/pt-br/azure/databricks/external-data/csv)\n",
    "* [Notebook Exemplo - CSV](https://docs.databricks.com/_extras/notebooks/source/read-csv-files.html)\n",
    "* [Salvando uma Tabela DELTA](https://docs.databricks.com/delta/tutorial.html#create-a-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05476df0-f786-4202-8ebe-2c2e500320ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Parâmetros Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9fc4c8-7d65-4977-8dd8-250ca00e47cf",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run \"./_setup/setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d315b07-222e-44f6-9ea3-00c09b009a66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print (f\"Seu catálogo e schema é: {catalogo}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a467ff1-53c5-45b2-9767-abdc27d98f09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "url = f\"https://raw.githubusercontent.com//Databricks-BR/lab_sql/main/dados/\"\n",
    "\n",
    "prefix_table = f\"bronze\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be65657-c09a-405d-9786-4542f6858c39",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - dolar"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name = f\"dolar\"\n",
    "\n",
    "table_name = f\"{catalogo}.{schema}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)  # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)  # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(\n",
    "    table_name\n",
    ")  # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23edce93-c276-4bc2-ad08-d9379e9ba226",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - CNAE"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"cnae\"\n",
    "\n",
    "table_name   = f\"{catalogo}.{schema}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5eb8337-343e-49fe-a29f-7716eca07c2d",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - empresas"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"empresas\"\n",
    "\n",
    "table_name   = f\"{catalogo}.{schema}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32069678-7caf-4318-8a95-af8f6438263e",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - estabelecimentos"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"estabelecimentos\"\n",
    "\n",
    "table_name   = f\"{catalogo}.{schema}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d016c9fb-f538-4534-9897-7b20478a541f",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - municipios"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"municipios\"\n",
    "\n",
    "table_name   = f\"{catalogo}.{schema}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90d01b9-0277-4c05-a443-9153262331cb",
     "showTitle": true,
     "title": "Gravando a tabela DELTA - naturezas"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "entity_name  = f\"naturezas\"\n",
    "\n",
    "table_name   = f\"{catalogo}.{schema}.{prefix_table}_{entity_name}\"\n",
    "file_name = f\"{url}{entity_name}.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)                          # leitura arquivo CSV utilizando Dataframe Pandas\n",
    "s_df = spark.createDataFrame(df)                     # converte Dataframe Pandas em Spark Dataframe\n",
    "s_df.write.mode(\"overwrite\").saveAsTable(table_name) # grava o DataFrame na Tabela Delta"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 597306790085131,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "lab02_01_carga_csv",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
